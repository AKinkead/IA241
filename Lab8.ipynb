{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job 1\n",
    "All Source Intelligence Analyst\n",
    "Northrop Grumman\n",
    "[link](https://www.google.com/search?q=intelligence+analyst+job+posting&rlz=1C1GCEU_enUS831US831&oq=intelligence+analyst+job+posting&aqs=chrome..69i57.8863j0j7&sourceid=chrome&ie=UTF-8&ibp=htl;jobs&sa=X&ved=2ahUKEwiSpu6m8JPhAhWut1kKHZTKAZMQiYsCKAF6BAgJECk#fpstate=tldetail&htidocid=KKkSE2_wKKdlrJJEAAAAAA%3D%3D&htivrt=job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job 2\n",
    "Senior Intelligence Analyst for Irregular Warfar\n",
    "Calhoun International\n",
    "[link](https://www.google.com/search?q=intelligence+analyst+job+posting&rlz=1C1GCEU_enUS831US831&oq=intelligence+analyst+job+posting&aqs=chrome..69i57.8863j0j7&sourceid=chrome&ie=UTF-8&ibp=htl;jobs&sa=X&ved=2ahUKEwiSpu6m8JPhAhWut1kKHZTKAZMQiYsCKAF6BAgJECk#fpstate=tldetail&htidocid=em58ePpoP7RnR5UxAAAAAA%3D%3D&htivrt=job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "  \n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "    \n",
    "with open('job1.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "     \n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('job1.xls')# define the location of your excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "  \n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "    \n",
    "with open('job2.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "     \n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('job2.xls')# define the location of your excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Job1cloud.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Job2cloud.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'construct', 'data', 'CYBERINTEL', 'assist', 'database;', 'Parametric', 'Action', 'Information', 'programmers', 'EEO/AA', 'performance', '3', 'class.', 'diverse', 'model', 'TS/SCI', 'employed.', 'simulation,', 'seeking', 'collaborate', 'complete', 'Equal', 'vulnerabilities,', 'orientation,', 'improved', 'scientific', 'engineering', 'preferred.', 'respond', 'Opportunity/Affirmative', '(9)', 'subsystems,', 'hiring', 'please', 'NGMSNVMSTR', 'most', \"Bachelor's\", 'committed', 'briefs,', 'five', 'protected', 'gender', 'area.', 'TTP', 'C-sUAS,', 'analysts', 'For', 'technical', 'analyze', 'willingness', 'capabilities;', 'be', 'gaps', 'contractor', 'qualitative', 'PRs', 'provide', 'Source', 'assessments;', '(SPIRIT)', 'U.S.', 'application', 'Unarmed', 'system,', 'existing', 'support', 'Preferred', 'C4', 'team', 'Performance', 'RFIs', 'Pay', 'by', 'remedy', 'assessment', 'military', 'applications', 'We', 'Characteristic', 'previous', 'modeling', 'electronic', '(sUAS)', 'signatures,', 'sUAS,', 'Relational', 'team.', 'part', 'SPIRIT', 'decisions', 'presentations', 'fully', 'active', 'age,', 'Tool', 'marital', 'Systems', 'suggestions', 'database.', 'commercial', 'join', 'military,', 'capabilities,', 'analytical,', 'narratives', 'foreign', 'civilian,', 'provides', 'desired,', 'nine', 'associated', 'pertaining', 'proud', 'Must', 'You', 'population', 'status,', 'subsystem,', 'school', 'Charlottesville,', 'can', 'the', 'conducting', 'Employer,', 'Northrop', 'timelines', 'required.', 'strong', 'government', 'who', 'creed,', 'veteran', 'leveraging', 'gather', 'and/or', 'make', 'www.northropgrumman.com/EEO.', 'processes', 'have', '(C&P)', 'force', 'characterize', 'demonstrate', 'sUAS', 'any', 'Ariel', 'signal', 'models', 'System', 'High', 'S&TI', 'composition', 'similar', 'limitations,', 'retaining', 'sexual', 'Basic', 'required,', 'disability,', 'modifications', 'Small', 'VA', 'workforce.', 'functionality', 'Transparency', 'positions', 'statement,', 'foundational', 'visit', 'candidates', 'identity,', 'recommendations', 'communication', 'Grumman', 'feedback', '(5)', 'practical,', 'required', 'studies', 'Qualifications', 'diploma', 'clearance.', 'author', 'Citizenship', 'degree', 'Youwill', 'While', 'individuals', 'making', 'origin,', 'technologies', 'characteristic'}\n",
      "{'Irregular', 'strategic', 'professional', 'Top', 'minimum', 'facilitate,', 'presentations,', 'innovative', 'developing', 'create,', 'incorporating', 'deliver', 'management.', 'products', 'revised', 'leadership', 'consideration', 'CRATE,', 'position', 'Excellent', 'TNAS', 'develop,', 'pages', 'accordance', 'Understanding', 'draft', 'evaluations,', 'standards,', 'M3,', 'Requirements', 'text', 'makers', '(RFIs),', 'meet', 'senior', 'Senior', 'US', 'requests', 'consulting', 'methodologies,', 'needs.', 'graphics', 'Degree.', 'responses.', 'clients.', 'trends,', 'communication,', 'stakeholders', 'solutions', 'Demonstrated', 'Army', 'standards', 'activities', 'consistent', 'instruction', 'providing', 'Develop,', 'HOT-R,', 'Washington,', 'management', 'Secret', 'briefing', 'ranges', 'customer', 'Such', 'Warfare', 'writing', 'analytic', 'cyberspace', 'Tampa,', 'developments', 'publications', 'processes,', 'responding', 'activity', 'Florida,', 'propose', 'provided', 'threat', 'complex', 'efforts', 'convey', 'Virginia,', 'NGIC', 'network', 'requirements.', 'training', 'Texas,', 'Ability', 'network,', 'operations', 'SCI', 'Familiarity', 'all', 'new', 'testing', 'papers.', 'significant', 'projects', 'well', 'Maryland,', 'excess', 'company', 'IC', 'Bachelors', 'information', 'knowledge', 'FL', 'expert', 'finished', 'source', 'qualified', 'Our', 'sensors,', 'multimedia', 'Current', 'systems', 'All-Source', '10', 'including', 'Responsibilities', 'from', 'D.C.', 'Government', 'Calhoun', 'applicants', 'reports', 'employees', 'overseas.', 'produce', 'located', 'Identify', 'DoD', 'commonly', 'producing,', 'reports,', 'across', 'policy', 'alert', 'programs', 'coordinating', 'concepts', 'CHROME/CORE', 'services', 'origin.', 'preparing,', 'RFI', 'International', 'briefings', 'briefings,', 'D,', 'NGT,', 'modeling,', 'receive', 'coordinate,', 'targeting', 'multiple', 'research,', 'RMT,', 'TRIPWIRE/TAC,'}\n"
     ]
    }
   ],
   "source": [
    "with open('job1.txt','r',encoding='utf-8', errors = 'ignore') as job1:\n",
    "    with open('job2.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str=job1.read()\n",
    "        job2_str=job2.read()\n",
    "        \n",
    "        job1_set=set(job1_str.split())\n",
    "        job2_set=set(job2_str.split())\n",
    "        \n",
    "        print (job1_set.difference(job2_set))\n",
    "        print (job2_set.difference(job1_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "with open('job1.txt','r',encoding='utf-8', errors = 'ignore') as job1:\n",
    "    with open('job2.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str=job1.read()\n",
    "        job2_str=job2.read()\n",
    "        print(fuzz.token_sort_ratio(job1_str, job2_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
